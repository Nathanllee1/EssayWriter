{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (open(\"training_data.txt\", encoding=\"utf-8\").read())\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, length - seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label = text[i + seq_length]\n",
    "    x.append([char_to_n[char] for char in sequence])\n",
    "    y.append(char_to_n[label])\n",
    "\n",
    "#shape input vectors to fit conv network\n",
    "X_modified = np.reshape(x, (len(x), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Sequential()\n",
    "\n",
    "model.add(LSTM(10, input_shape=(X_modified.shape[1], X_modified.shape[2]), \n",
    "               return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(10))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint_ = ModelCheckpoint(filepath='.\\models\\weights.{epoch:02d}--{val_loss:.2f}.hdf5', verbose=1, save_best_only=True)\n",
    "EarlyStopping_ = EarlyStopping(monitor='val_loss', min_delta=0.06, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "#tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PredictModel(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        string_mapped = x[99]\n",
    "        # generating characters\n",
    "        string_mapped = x[99]\n",
    "        full_string = [n_to_char[value] for value in string_mapped]\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "            x = x / float(len(characters))\n",
    "\n",
    "            pred_index = np.argmax(model.predict(x, verbose=2))\n",
    "            seq = [n_to_char[value] for value in string_mapped]\n",
    "            full_string.append(n_to_char[pred_index])\n",
    "\n",
    "            string_mapped.append(pred_index)\n",
    "            string_mapped = string_mapped[1:len(string_mapped)]\n",
    "        txt=\"\"\n",
    "        for char in full_string:\n",
    "            txt = txt+char\n",
    "\n",
    "        print(txt)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77688/77688 [==============================] - 123s 2ms/step - loss: 2.9778\n",
      "Epoch 2/100\n",
      "14300/77688 [====>.........................] - ETA: 1:38 - loss: 2.9645"
     ]
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=100, batch_size=50)\n",
    "#callbacks=[modelcheckpoint_, EarlyStopping_, PredictModel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = glob.glob('\\models\\.hdf5') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "model.load_weights(latest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
